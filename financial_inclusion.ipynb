{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200}\n",
      "Accuracy: 0.8913921360255048\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      4063\n",
      "           1       0.75      0.30      0.43       642\n",
      "\n",
      "    accuracy                           0.89      4705\n",
      "   macro avg       0.83      0.64      0.69      4705\n",
      "weighted avg       0.88      0.89      0.87      4705\n",
      "\n",
      "Model saved as rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle  # Importing pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# Load the dataset\n",
    "dataset_path = \"C:/Users/dell/Downloads/Checkpoint2/Financial_inclusion_dataset.csv\"  # Adjust the path to match your dataset location\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    exit()\n",
    "# Drop unnecessary columns\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = [\n",
    "    \"country\",\n",
    "    \"location_type\",  # Removed 'bank_account' from this list\n",
    "    \"cellphone_access\",\n",
    "    \"gender_of_respondent\",\n",
    "    \"relationship_with_head\",\n",
    "    \"marital_status\",\n",
    "    \"education_level\",\n",
    "    \"job_type\",\n",
    "]\n",
    "target_column = \"bank_account\"  # Assuming this is the target variable\n",
    "\n",
    "# Encoding the target variable\n",
    "le = LabelEncoder()\n",
    "df[target_column] = le.fit_transform(df[target_column])\n",
    "\n",
    "# Define feature matrix (X) and target vector (y)\n",
    "X = df.drop(columns=[target_column, 'uniqueid'])  # Dropping 'uniqueid' here\n",
    "y = df[target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing for categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # Pass through numerical columns\n",
    ")\n",
    "\n",
    "# Define the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up a pipeline\n",
    "pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", rf)])\n",
    "\n",
    "# Set up GridSearchCV parameters\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200, 300],\n",
    "    \"classifier__max_depth\": [10, 20, None],\n",
    "    \"classifier__min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=3, scoring=\"accuracy\", verbose=3, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model for Streamlit using pickle\n",
    "with open(\"rf_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(grid_search.best_estimator_, file)\n",
    "print(\"Model saved as rf_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
